import pandas as pd
import numpy as np
import re
from pathlib import Path
from wordcloud import WordCloud
import matplotlib.pyplot as plt
import seaborn as sns
import warnings

warnings.filterwarnings('ignore')

# --- æ¸…æ´—å‡½æ•° ---
def parse_salary_value(num_str, unit):
    """æ ¹æ®æ˜ç¡®çš„å•ä½æ¥è§£ææ•°å€¼"""
    try:
        num = float(num_str)
        if unit == 'ä¸‡':
            return num * 10  # ç»Ÿä¸€è½¬æ¢ä¸ºåƒ
        if unit == 'åƒ':
            return num
        if unit == 'å…ƒ/å¤©':
            return num * 21.75 / 1000 # æŒ‰æ¯æœˆ21.75ä¸ªå·¥ä½œæ—¥è®¡ç®—ï¼Œå¹¶è½¬æ¢ä¸ºåƒ
        return num # å¦‚æœæ²¡æœ‰å•ä½ï¼Œåˆ™å‡å®šä¸ºåƒ
    except (ValueError, TypeError):
        return np.nan

def clean_salary(salary_str):
    """
    ã€æœ€ç»ˆå¥å£®ç‰ˆã€‘è–ªèµ„æ¸…æ´—å‡½æ•°ï¼Œèƒ½æ­£ç¡®å¤„ç†å•ä½ä¸ä¸€è‡´å’Œæ—¥è–ªç­‰å¤æ‚æƒ…å†µã€‚
    """
    if pd.isna(salary_str) or not isinstance(salary_str, str) or 'é¢è®®' in salary_str:
        return np.nan, np.nan

    salary_str = salary_str.strip()
    
    # ä¼˜å…ˆå¤„ç†æ—¥è–ªæƒ…å†µ
    if 'å…ƒ/å¤©' in salary_str:
        nums = re.findall(r'(\d+\.?\d*)', salary_str)
        if nums:
            daily_salary = float(nums[0])
            # å°†æ—¥è–ªè½¬æ¢ä¸ºæœˆè–ªï¼ˆåƒå…ƒå•ä½ï¼‰
            monthly_k = daily_salary * 21.75 / 1000
            return round(monthly_k, 1), round(monthly_k, 1)
        return np.nan, np.nan

    # è¯†åˆ«ä¸»è¦å•ä½ï¼ˆä¸‡ã€åƒï¼‰
    unit = 'åƒ' # é»˜è®¤å•ä½
    if 'ä¸‡' in salary_str:
        unit = 'ä¸‡'
    
    # å»æ‰ç¦åˆ©æè¿°ï¼Œå¦‚ "Â·15è–ª"
    salary_str = salary_str.split('Â·')[0]
    
    # æå–æ‰€æœ‰æ•°å­—éƒ¨åˆ†
    nums = re.findall(r'(\d+\.?\d*)', salary_str)
    
    if len(nums) == 0:
        return np.nan, np.nan
    
    if len(nums) == 1:
        # å•ä¸ªè–ªèµ„ï¼Œå¦‚ "1.5ä¸‡"
        val = parse_salary_value(nums[0], unit)
        return round(val, 1), round(val, 1)
    
    if len(nums) >= 2:
        # è–ªèµ„èŒƒå›´ï¼Œå¦‚ "1-1.5ä¸‡" æˆ– "8åƒ-1.2ä¸‡"
        min_val_str, max_val_str = nums[0], nums[1]
        
        # å…³é”®é€»è¾‘ï¼šå¦‚æœmax_val_stråé¢æœ‰'ä¸‡'ï¼Œåˆ™min_val_strä¹Ÿåº”è¯¥æŒ‰'ä¸‡'å¤„ç†
        # é€‚ç”¨äº "8åƒ-1.2ä¸‡" -> 8åƒ, 12åƒ çš„æƒ…å†µ
        temp_parts = salary_str.split('-')
        min_unit = 'åƒ' if 'åƒ' in temp_parts[0] else unit
        max_unit = 'ä¸‡' if 'ä¸‡' in temp_parts[1] else unit

        # å¦‚æœæœ€å¤§å€¼å•ä½æ˜¯ä¸‡ï¼Œæœ€å°å€¼å•ä½æ˜¯åƒï¼Œä½†æœ€å°å€¼å¤§äº10ï¼ˆä¸åˆç†ï¼‰ï¼Œåˆ™è®¤ä¸ºå®ƒä¹Ÿæ˜¯ä¸‡
        if max_unit == 'ä¸‡' and min_unit == 'åƒ' and float(min_val_str) > 10:
             min_unit = 'ä¸‡'
        
        # ä¿®æ­£ "1-1.5ä¸‡" çš„æƒ…å†µï¼Œè®© '1' ç»§æ‰¿ 'ä¸‡' çš„å•ä½
        if 'ä¸‡' in temp_parts[1] and 'åƒ' not in temp_parts[0] and 'ä¸‡' not in temp_parts[0]:
            min_unit = 'ä¸‡'

        min_val = parse_salary_value(min_val_str, min_unit)
        max_val = parse_salary_value(max_val_str, max_unit)
        
        return round(min_val, 1), round(max_val, 1)
        
    return np.nan, np.nan

def process_data(input_path, output_path):
    """ã€æœ€ç»ˆå¥å£®ç‰ˆã€‘å®Œæ•´çš„æ•°æ®æ¸…æ´—å’Œå¤„ç†æµç¨‹"""
    try:
        df = pd.read_csv(input_path)
    except FileNotFoundError:
        print(f"é”™è¯¯ï¼šæ‰¾ä¸åˆ° {input_path}ã€‚è¯·å…ˆè¿è¡Œçˆ¬è™«ã€‚")
        return pd.DataFrame()

    df.columns = df.columns.str.strip()
    df.dropna(subset=['jobId'], inplace=True)
    df.drop_duplicates(subset=['jobId'], inplace=True)
    df[['min_salary', 'max_salary']] = df['jobSalary'].apply(clean_salary).apply(pd.Series)
    df['avg_salary'] = (df['min_salary'] + df['max_salary']) / 2
    df['city'] = df['jobArea'].apply(lambda x: str(x).split('-')[0] if pd.notna(x) else np.nan)
    df.dropna(subset=['avg_salary', 'city'], inplace=True)
    
    if df.empty:
        print("ã€è­¦å‘Šã€‘æ‰€æœ‰æ•°æ®åœ¨æ¸…æ´—åè¢«è¿‡æ»¤ã€‚")
        return pd.DataFrame()

    df.rename(columns={
        'jobTitle': 'èŒä½åç§°', 'companyName': 'å…¬å¸åç§°', 'jobYear': 'ç»éªŒè¦æ±‚',
        'jobDegree': 'å­¦å†è¦æ±‚', 'companyTypeString': 'å…¬å¸æ€§è´¨', 'companySizeString': 'å…¬å¸è§„æ¨¡',
        'jobLabel': 'æŠ€èƒ½æ ‡ç­¾', 'jobHref': 'è¯¦æƒ…é“¾æ¥', 'city': 'åŸå¸‚','min_salary': 'æœ€ä½è–ªèµ„',
        'max_salary': 'æœ€é«˜è–ªèµ„','avg_salary': 'å¹³å‡è–ªèµ„'
    }, inplace=True)
    
    final_cols = [
        'èŒä½åç§°', 'å…¬å¸åç§°', 'åŸå¸‚', 'æœ€ä½è–ªèµ„', 'æœ€é«˜è–ªèµ„', 'å¹³å‡è–ªèµ„',
        'ç»éªŒè¦æ±‚', 'å­¦å†è¦æ±‚', 'å…¬å¸æ€§è´¨', 'å…¬å¸è§„æ¨¡', 'æŠ€èƒ½æ ‡ç­¾', 'è¯¦æƒ…é“¾æ¥'
    ]
    df_cleaned = df[[col for col in final_cols if col in df.columns]]
    
    df_cleaned.to_csv(output_path, index=False, encoding='utf-8-sig')
    print(f"\næ•°æ®æ¸…æ´—å®Œæˆï¼æœ€ç»ˆæˆåŠŸå¤„ç†äº† {len(df_cleaned)} æ¡æœ‰æ•ˆæ•°æ®ã€‚")
    print(f"æ¸…æ´—åçš„æ•°æ®å·²ä¿å­˜è‡³ '{output_path}'")
    return df_cleaned

# å¯è§†åŒ–å‡½æ•° analyze_and_visualize 
def analyze_and_visualize(df, output_dir):
    plt.style.use('seaborn-v0_8-whitegrid')
    plt.rcParams['font.sans-serif'] = ['SimHei']
    plt.rcParams['axes.unicode_minus'] = False
    
    city_counts = df['åŸå¸‚'].value_counts().nlargest(10)
    plt.figure(figsize=(12, 7)); sns.barplot(x=city_counts.index, y=city_counts.values, palette='viridis')
    plt.title('Pythonå²—ä½æ•°é‡Top10åŸå¸‚', fontsize=16); plt.xlabel('åŸå¸‚', fontsize=12); plt.ylabel('å²—ä½æ•°é‡', fontsize=12)
    plt.xticks(rotation=45, ha='right'); plt.tight_layout(); plt.savefig(f'{output_dir}/job_counts_by_city.png')
    print("å·²ç”Ÿæˆ 'å²—ä½æ•°é‡Top10åŸå¸‚' å›¾è¡¨ã€‚")

    city_salary = df[df['åŸå¸‚'].isin(city_counts.index)].groupby('åŸå¸‚')['å¹³å‡è–ªèµ„'].mean().sort_values(ascending=False)
    plt.figure(figsize=(12, 7)); sns.barplot(x=city_salary.index, y=city_salary.values, palette='plasma')
    plt.title('Top10çƒ­é—¨åŸå¸‚å¹³å‡è–ªèµ„ (åƒ/æœˆ)', fontsize=16); plt.xlabel('åŸå¸‚', fontsize=12); plt.ylabel('å¹³å‡è–ªèµ„ (K/æœˆ)', fontsize=12)
    plt.xticks(rotation=45, ha='right'); plt.tight_layout(); plt.savefig(f'{output_dir}/salary_by_city.png')
    print("å·²ç”Ÿæˆ 'Top10çƒ­é—¨åŸå¸‚å¹³å‡è–ªèµ„' å›¾è¡¨ã€‚")

    all_labels = df['æŠ€èƒ½æ ‡ç­¾'].dropna().astype(str)
    if not all_labels.empty:
        text = " ".join(label.strip() for label in all_labels.str.cat(sep=',').split(',') if label.strip())
        if text:
            stopwords = set(['Python', 'python', 'åç«¯', 'å¼€å‘', 'å·¥ç¨‹å¸ˆ', 'é¢è®®'])
            wordcloud = WordCloud(font_path='C:/Windows/Fonts/simhei.ttf', width=1000, height=500, background_color='white', stopwords=stopwords, collocations=False, max_words=100).generate(text)
            plt.figure(figsize=(15, 8)); plt.imshow(wordcloud, interpolation='bilinear'); plt.title('å²—ä½çƒ­é—¨æŠ€èƒ½éœ€æ±‚è¯äº‘', fontsize=20); plt.axis('off'); plt.savefig(f'{output_dir}/skills_wordcloud.png')
            print("å·²ç”Ÿæˆ 'æŠ€èƒ½å…³é”®è¯è¯äº‘' å›¾è¡¨ã€‚")
        else:
            print("æŠ€èƒ½æ ‡ç­¾å†…å®¹ä¸ºç©ºï¼Œè·³è¿‡ç”Ÿæˆè¯äº‘ã€‚")
    else:
        print("æ— æœ‰æ•ˆçš„æŠ€èƒ½æ ‡ç­¾æ•°æ®ï¼Œè·³è¿‡ç”Ÿæˆè¯äº‘ã€‚")

if __name__ == '__main__':
    # ä» analysis ç›®å½•ä¸Šå‡åˆ°é¡¹ç›®æ ¹ç›®å½•
    BASE_DIR = Path(__file__).resolve().parent.parent 
    
    # å®šä¹‰æ•°æ®æ–‡ä»¶å’Œè¾“å‡ºç›®å½•çš„ç»å¯¹è·¯å¾„
    RAW_DATA_PATH = BASE_DIR / 'data' / 'jobs_raw.csv'
    CLEANED_DATA_PATH = BASE_DIR / 'data' / 'jobs_cleaned.csv'
    OUTPUT_DIR = BASE_DIR / 'output'

    print(f"ğŸš€ å¼€å§‹å¤„ç†æ•°æ®: {RAW_DATA_PATH}")
    cleaned_df = process_data(RAW_DATA_PATH, CLEANED_DATA_PATH)
    
    if cleaned_df is not None and not cleaned_df.empty:
        print("âœ… æ•°æ®æ¸…æ´—å®Œæˆã€‚")
        print("ğŸ“Š å¼€å§‹ç”Ÿæˆåˆ†æå›¾è¡¨...")
        analyze_and_visualize(cleaned_df, OUTPUT_DIR)
        print(f"\nğŸ‰ æ‰€æœ‰åˆ†æå›¾è¡¨å·²ç”Ÿæˆå¹¶ä¿å­˜åˆ° '{OUTPUT_DIR}' ç›®å½•ã€‚")
    else:
        print("\nğŸ›‘ æ•°æ®å¤„ç†å¤±è´¥æˆ–å¤„ç†åä¸ºç©ºï¼Œæ— æ³•è¿›è¡Œåˆ†æã€‚")