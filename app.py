import streamlit as st
import pandas as pd
import os

# è·å–å½“å‰app.pyæ–‡ä»¶æ‰€åœ¨çš„ç›®å½•
BASE_DIR = os.path.dirname(os.path.abspath(__file__))

# åŸºäºè¯¥ç›®å½•æ„å»ºæ•°æ®å’Œå›¾è¡¨æ–‡ä»¶çš„ã€ç»å¯¹è·¯å¾„ã€‘
DATA_DIR = os.path.join(BASE_DIR, 'data')
CLEANED_DATA_PATH = os.path.join(DATA_DIR, 'jobs_cleaned.csv')
OUTPUT_DIR = os.path.join(BASE_DIR, 'output')
CITY_COUNT_IMG_PATH = os.path.join(OUTPUT_DIR, 'job_counts_by_city.png')
CITY_SALARY_IMG_PATH = os.path.join(OUTPUT_DIR, 'salary_by_city.png')
SKILLS_WORDCLOUD_IMG_PATH = os.path.join(OUTPUT_DIR, 'skills_wordcloud.png')

# åˆ›å»º data æ–‡ä»¶å¤¹ (å¦‚æœå®ƒä¸å­˜åœ¨)
if not os.path.exists(DATA_DIR):
    os.makedirs(DATA_DIR)
    print(f"ğŸ“‚ ç›®å½• '{DATA_DIR}' å·²åˆ›å»ºã€‚")

# åˆ›å»º output æ–‡ä»¶å¤¹ (å¦‚æœå®ƒä¸å­˜åœ¨)
if not os.path.exists(OUTPUT_DIR):
    os.makedirs(OUTPUT_DIR)
    print(f"ğŸ“‚ ç›®å½• '{OUTPUT_DIR}' å·²åˆ›å»ºã€‚")

# --- é¡µé¢ä¸»é€»è¾‘ ---
st.set_page_config(page_title="PythonèŒä½å¸‚åœºåˆ†æçœ‹æ¿", layout="wide")

st.title("Python èŒä½å¸‚åœºåˆ†æçœ‹æ¿")
st.write("æ•°æ®æ¥æºï¼šå‰ç¨‹æ— å¿§ (51job.com)")

# æ£€æŸ¥æ‰€æœ‰å¿…éœ€çš„æ–‡ä»¶æ˜¯å¦å­˜åœ¨
required_files_exist = os.path.exists(CLEANED_DATA_PATH) and \
                       os.path.exists(CITY_COUNT_IMG_PATH) and \
                       os.path.exists(CITY_SALARY_IMG_PATH)

# å¦‚æœæ–‡ä»¶ä¸é½å…¨ï¼Œæ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
if not required_files_exist:
    st.error("é”™è¯¯ï¼šå¿…éœ€çš„æ•°æ®æˆ–å›¾è¡¨æ–‡ä»¶ä¸å­˜åœ¨ï¼")
    st.info("è¯·æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤æ“ä½œï¼š")
    st.code("""
    1. ç¡®ä¿ä½ çš„ç»ˆç«¯ä½äºé¡¹ç›®æ ¹ç›®å½• (JobAnalysis) ä¸‹ã€‚
    2. è¿è¡Œçˆ¬è™«: python scraper/job_scraper.py
    3. è¿è¡Œåˆ†æå™¨: python analysis/data_analyzer.py
    4. é‡æ–°å¯åŠ¨Streamlitåº”ç”¨: streamlit run app.py
    """)
    # é¢å¤–æä¾›è°ƒè¯•ä¿¡æ¯ï¼Œæ˜¾ç¤ºç¨‹åºæ­£åœ¨æŸ¥æ‰¾çš„è·¯å¾„
    st.subheader("è°ƒè¯•ä¿¡æ¯ï¼š")
    st.write(f"æ­£åœ¨æŸ¥æ‰¾æ•°æ®æ–‡ä»¶äº: `{CLEANED_DATA_PATH}` - {'æ‰¾åˆ°' if os.path.exists(CLEANED_DATA_PATH) else 'æœªæ‰¾åˆ°'}")
    st.write(f"æ­£åœ¨æŸ¥æ‰¾å›¾è¡¨1äº: `{CITY_COUNT_IMG_PATH}` - {'æ‰¾åˆ°' if os.path.exists(CITY_COUNT_IMG_PATH) else 'æœªæ‰¾åˆ°'}")
    st.write(f"æ­£åœ¨æŸ¥æ‰¾å›¾è¡¨2äº: `{CITY_SALARY_IMG_PATH}` - {'æ‰¾åˆ°' if os.path.exists(CITY_SALARY_IMG_PATH) else 'æœªæ‰¾åˆ°'}")

# å¦‚æœæ–‡ä»¶éƒ½å­˜åœ¨ï¼Œåˆ™æ­£å¸¸æ˜¾ç¤ºå†…å®¹
else:
    st.header("çƒ­é—¨åŸå¸‚åˆ†æ")
    col1, col2 = st.columns(2)
    with col1:
        st.image(CITY_COUNT_IMG_PATH, caption='Top 10 åŸå¸‚Pythonå²—ä½æ•°é‡', use_column_width=True)
    with col2:
        st.image(CITY_SALARY_IMG_PATH, caption='Top 10 çƒ­é—¨åŸå¸‚å¹³å‡æœˆè–ª (K/æœˆ)', use_column_width=True)

    # è¯äº‘å›¾æ˜¯å¯é€‰çš„ï¼Œå•ç‹¬æ£€æŸ¥å®ƒæ˜¯å¦å­˜åœ¨
    if os.path.exists(SKILLS_WORDCLOUD_IMG_PATH):
        st.header("çƒ­é—¨æŠ€èƒ½éœ€æ±‚")
        st.image(SKILLS_WORDCLOUD_IMG_PATH, caption='å²—ä½æŠ€èƒ½éœ€æ±‚è¯äº‘', use_column_width=True)
    else:
        st.warning("æŠ€èƒ½éœ€æ±‚è¯äº‘å›¾æœªç”Ÿæˆï¼Œå¯èƒ½æ˜¯åŸå§‹æ•°æ®ä¸­ç¼ºå°‘ç›¸å…³æ ‡ç­¾ã€‚")

    st.header("èŒä½æ•°æ®è¯¦æƒ…")
    try:
        df = pd.read_csv(CLEANED_DATA_PATH)
        # ä½¿ç”¨st.dataframeå¯ä»¥æ›´å¥½åœ°å±•ç¤ºè¡¨æ ¼ï¼Œå¹¶æä¾›äº¤äº’åŠŸèƒ½
        st.dataframe(df)
    except Exception as e:
        st.error(f"åŠ è½½æ•°æ®è¡¨æ ¼å¤±è´¥: {e}")

